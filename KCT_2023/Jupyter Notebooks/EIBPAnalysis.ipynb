{"cells":[{"cell_type":"markdown","id":"3f6e805a-b424-467c-9804-515fc791787e","metadata":{"tags":[],"id":"3f6e805a-b424-467c-9804-515fc791787e"},"source":["# Analyze EIBP Log Results"]},{"cell_type":"markdown","id":"afde3953-6a77-4959-b953-fda62daf9a75","metadata":{"id":"afde3953-6a77-4959-b953-fda62daf9a75"},"source":["## Input Required Information\n","\n","| Variable | Use |\n","| --- | --- |\n","| LOG_DIR_PATH | Location of the log directory. |"]},{"cell_type":"code","execution_count":null,"id":"1f37ce88-0f0d-431b-8506-946f5dbf09a5","metadata":{"tags":[],"id":"1f37ce88-0f0d-431b-8506-946f5dbf09a5"},"outputs":[],"source":["LOG_DIR_PATH = \"/home/fabric/work/FABRIC-Automation-main/logs\""]},{"cell_type":"code","execution_count":null,"id":"1d1bc346-4898-4fcc-800b-d717e9db6430","metadata":{"tags":[],"id":"1d1bc346-4898-4fcc-800b-d717e9db6430","outputId":"0ad1d228-c663-447d-d3bd-24702118e4a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["CONVERGENCE_TIME: 0.5672049522399902 s\n","OVERHEAD: 1472 bytes\n","CHURN PERCENTAGE: 80.00%\n"]}],"source":["import re\n","import os\n","\n","# initialize variables for calculating sum of eth_size, checking churn, and finding max conv_time\n","max_convergence_time = float('-inf')\n","sum_eth_size = 0\n","churn_count = 0\n","total_files = 0\n","min_down_time = float('+inf')\n","\n","# define a regular expression to match the required lines\n","pattern = re.compile(r'^CONV_TIME:(\\d+\\.\\d+)$')\n","\n","# get the value for down_time from the log files\n","down_time_pattern = re.compile(r'^IF_TIMER_DOWN:(\\d+\\.\\d+)$')\n","dir_down_time_pattern = re.compile(r'^IF_DIRECT_DOWN:(\\d+\\.\\d+)$')\n","\n","\n","# loop through all files in the current directory\n","for filename in os.listdir(LOG_DIR_PATH):\n","    if filename.endswith('.log'):\n","        # open the file and loop through each line\n","        with open(os.path.join(LOG_DIR_PATH,filename), 'r') as file:\n","            for line in file:\n","                # check if the line matches the down_time pattern\n","                match = down_time_pattern.match(line.strip())\n","                match1 = dir_down_time_pattern.match(line.strip())\n","                if match:\n","                    # extract the down_time value from the line\n","                    down_time = float(match.group(1))\n","                    # update min_down_time if necessary\n","                    if down_time < min_down_time:\n","                        min_down_time = down_time\n","\n","                if match1:\n","                    # extract the down_time value from the line\n","                    down_time = float(match1.group(1))\n","                    # update min_down_time if necessary\n","                    if down_time < min_down_time:\n","                        min_down_time = down_time\n","\n","down_time = min_down_time\n","\n","# loop through all files in the current directory again to calculate the other values\n","for filename in os.listdir(LOG_DIR_PATH):\n","    if filename.endswith('.log'):\n","        total_files += 1\n","        # open the file and loop through each line\n","        with open(os.path.join(LOG_DIR_PATH,filename), 'r') as file:\n","            # initialize variables for this file\n","            file_sum_eth_size = 0\n","            file_churn = False\n","            file_max_conv_time = float('-inf')\n","            for line in file:\n","                # check if the line matches the pattern\n","                match = pattern.match(line.strip())\n","                if match:\n","                    # get the next line that contains ETH_SIZE\n","                    eth_size_line = file.readline().strip()\n","                    # extract the values from the lines\n","                    conv_time = float(match.group(1))\n","                    eth_size = int(eth_size_line.split(':')[1])\n","                    # add eth_size to file_sum if conv_time is greater than down_time\n","                    if conv_time > down_time:\n","                        file_sum_eth_size += eth_size\n","                        # check if the next line contains CHURN_TRUE\n","                        churn_true_line = file.readline().strip()\n","                        if churn_true_line == 'CHURN_TRUE':\n","                            file_churn = True\n","                    # update file_max_conv_time if necessary\n","                    if conv_time > file_max_conv_time:\n","                        file_max_conv_time = conv_time\n","            # update global variables with values for this file\n","            if file_max_conv_time > max_convergence_time:\n","                max_convergence_time = file_max_conv_time\n","            sum_eth_size += file_sum_eth_size\n","            if file_churn:\n","                churn_count += 1\n","\n","# calculate percentage of files with churn true\n","if total_files > 0:\n","    churn_percent = (churn_count / total_files) * 100\n","else:\n","    churn_percent = 0\n","\n","# calculate the difference between max_conv_time and down_time\n","convergence_time = max_convergence_time - down_time\n","\n","# display the result\n","print(f\"CONVERGENCE_TIME: {convergence_time} s\")\n","print(f\"OVERHEAD: {sum_eth_size} bytes\")\n","print(f\"CHURN PERCENTAGE: {churn_percent:.2f}%\")"]},{"cell_type":"code","execution_count":null,"id":"6fbcc41a-d8a7-45b6-8326-510884c61985","metadata":{"tags":[],"id":"6fbcc41a-d8a7-45b6-8326-510884c61985"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}